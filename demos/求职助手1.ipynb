{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"嗨，感谢您的邀请！我目前确实有换工作的意愿，想寻找一个挑战性的角色和良好的团队文化。我对加入您的团队感到非常兴奋，能否了解更多关于这个岗位的信息？\"\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_fireworks import ChatFireworks\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3-70b-instruct\",temperature=0)\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(\"你是一个求职助手，用汉语交流。\")\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\"HR问或说：“{user_input}”，你用汉语回答：\")\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt,\n",
    "     human_message_prompt]\n",
    ")\n",
    "chain = chat_prompt|llm|StrOutputParser()\n",
    "text = \"\"\"\n",
    "请问，最近有换工作的意愿么？我们正在寻找一位团队伙伴。\n",
    "\"\"\"\n",
    "messages = chat_prompt.format_prompt(user_input=text)\n",
    "print(chain.invoke(messages))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分割后快数: 140\n",
      "索引片段数: 140\n"
     ]
    }
   ],
   "source": [
    "# 完整的求职检索链\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter,CharacterTextSplitter\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from dotenv import load_dotenv\n",
    "from langchain_fireworks import FireworksEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "load_dotenv()\n",
    "# 文档加载、分割\n",
    "loader = WebBaseLoader(\"https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt\")\n",
    "raw_documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    add_start_index=False,\n",
    ")\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "print(f\"分割后快数: {len(documents)}\")\n",
    "# 向量化、存储\n",
    "embedding_model = FireworksEmbeddings(model=\"nomic-ai/nomic-embed-text-v1.5\")\n",
    "db = FAISS.from_documents(documents=documents, embedding=embedding_model)\n",
    "print(f\"索引片段数: {db.index.ntotal}\")\n",
    "# 检索器\n",
    "retriever = db.as_retriever()\n",
    "# 检索链 返回检索结果字符串\n",
    "question_retrieval_chain = retriever | RunnableLambda(lambda docs: \"\\n\".join([doc.page_content for doc in docs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "长文本的预测。语种识别，汉英分词与关键词抽取。受模型对输入文本长度的限制，也是为了确保模型预测准确性，对于所有输入文本，加入预处理步骤，执行语种识别，分词和关键词抽取，将抽取出的关键词送入模型进行预\n",
      "•\t商品标题分类项目\n",
      "]\n",
      "}\n",
      "•\t社交短文本分类项目\n",
      "1. 数据的获取\n",
      "•\t社交短文本实体识别项目\n"
     ]
    }
   ],
   "source": [
    "print(question_retrieval_chain.invoke(\"文本分类\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/feiyu/miniconda3/envs/langchain-py11/lib/python3.11/site-packages/langchain_core/utils/utils.py:161: UserWarning: WARNING! top_p is not default parameter.\n",
      "                top_p was transferred to model_kwargs.\n",
      "                Please confirm that top_p is what you intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'两周内到岗。'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 完整的问题分类链\n",
    "from langchain_fireworks import ChatFireworks\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import re\n",
    "from langchain_core.prompts import FewShotPromptTemplate,PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "# 实例化聊天模型\n",
    "chat = ChatFireworks(model=\"accounts/fireworks/models/llama-v3-70b-instruct\", \n",
    "                    temperature=0.3,\n",
    "                    top_p=0.3)\n",
    "# 分类词典\n",
    "question_classify_dict = {\n",
    "    \"离职原因\": {\n",
    "        \"response\": \"有换工意愿，上家公司离我居住地太远，通勤时间太长。\",\n",
    "        \"examples\": [{\"text\": \"离职/换工作的原因\",\"label\": \"离职原因\"}]\n",
    "    },\n",
    "    \"薪资\": {\n",
    "        \"response\": \"我期望薪资为30K～40K。\",\n",
    "        \"examples\": [{\"text\": \"但是我们应该最高30K，一般还达不到.\",\"label\": \"薪资\"}]\n",
    "    },\n",
    "    \"外包&外协&外派&驻场\": {\n",
    "        \"response\": \"请发送或说明职位的办公地点定位。以及薪资范围。我期望薪资范围30-40K？\",\n",
    "        \"examples\": [{\"text\": \"你好，我们是外协岗位，在国家电网 南瑞工作的\",\"label\": \"外包&外协&外派&驻场\"}]\n",
    "    },\n",
    "    \"兼职\": {\n",
    "        \"response\": \"职位的办公地点在哪？薪资多少，怎么结算？\",\n",
    "        \"examples\": [{\"text\": \"哈喽～本职位为线上兼职，一单一结款，根据自己时间自由接单，不耽误自己的主业，您看感兴趣嘛？\",\"label\":\"兼职\"}]\n",
    "    },\n",
    "    \"预约面试\": {\n",
    "        \"response\": \"本周内上午、下午都有时间。\",\n",
    "        \"examples\": [{\"text\": \"想约您面试，方便的话麻烦告诉我一下您可以约面试的日期及时间【请选择工作日内的上午10-12点或下午14点到17点内的时间】。\",\"label\":\"预约面试\"}]\n",
    "    },\n",
    "    \"到岗时间\": {\n",
    "        \"response\": \"两周内到岗。\",\n",
    "        \"examples\": [{\"text\": \"咱到岗时间呢。\",\"label\":\"到岗时间\"}]\n",
    "    },\n",
    "    \"其他\": {\n",
    "        \"response\": \"\",\n",
    "        \"examples\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "# 准备分类提示所需信息\n",
    "def prepare_question_classify_prompt():\n",
    "    # [问题分类链] 构造问题分类示例集\n",
    "    examples = []\n",
    "    for key in question_classify_dict:\n",
    "        r_examples = question_classify_dict[key][\"examples\"]\n",
    "        if len(r_examples) > 0:\n",
    "            examples.extend(r_examples)\n",
    "    # [问题分类链] 分类示例模板 作用就是格式化分类示例\n",
    "    example_prompt = PromptTemplate.from_template(\n",
    "        \"\"\"文本: {text}\n",
    "        类别: {label}\n",
    "        \"\"\"\n",
    "    )\n",
    "    # [问题分类链] 写在所有示例之前的分类要求\n",
    "    prefix = f\"\"\"\n",
    "    给出每个文本的类别，类别只能属于以下列出的一种\n",
    "\n",
    "    {\"- \".join(question_classify_dict.keys())}\n",
    "\n",
    "    如果不属于以上类别，则类别名称为“其他”。\n",
    "\n",
    "    例如：\n",
    "    \"\"\"\n",
    "    # [问题分类链] 写在所有示例之后的内容，提示LLM对当前input进行分类\n",
    "    suffix = \"\"\"文本: {input}\\n类别:\n",
    "    \"\"\"\n",
    "    return examples,example_prompt,prefix,suffix\n",
    "\n",
    "# 构建分类提示\n",
    "examples,example_prompt,prefix,suffix = prepare_question_classify_prompt()\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\"\n",
    ")\n",
    "\n",
    "# 由分类标签生成分类响应\n",
    "def label_to_response(label):\n",
    "    label = re.sub('类别: ?', '', label)\n",
    "    label = label if label in question_classify_dict else \"其他\"\n",
    "    response = question_classify_dict[label][\"response\"]\n",
    "    return response\n",
    "\n",
    "# 分类链 返回分类响应字符串\n",
    "question_classify_chain = few_shot_prompt | chat | StrOutputParser()|RunnableLambda(label_to_response)\n",
    "question_classify_chain.invoke(\"何时到岗？\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Weaver是一款自然语言处理工具，主要用于文本生成和编辑。它可以根据用户的输入，生成高质量的文本，例如文章、邮件、报告等。Word Weaver使用了先进的算法和机器学习技术，能够理解用户的意图和需求，生成符合要求的文本。\n",
      "\n",
      "在我的研究生涯中，我曾经参与过自然语言处理相关的项目，了解到Word Weaver的原理和应用场景。虽然我没有直接使用过Word Weaver，但我认为它是一款非常有用的工具，能够提高文本生成和编辑的效率和质量。\n",
      "\n",
      "如果贵公司需要自然语言处理方面的技术支持，我愿意提供帮助和建议。\n"
     ]
    }
   ],
   "source": [
    "# 合并分类链检索链构建完整链\n",
    "from langchain_core.runnables import RunnableParallel,RunnablePassthrough,RunnableLambda\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 系统提示\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(f\"\"\"\n",
    "你是求职助手于先生。刚从中国科学院信息工程研究所离职。居住地为北京。\n",
    "\"\"\")\n",
    "# 人工提示\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "HR问或说: {question}。\n",
    "\n",
    "{context}\n",
    "\n",
    "请用汉语回复内容，内容的头部和尾部不要出现引号。\n",
    "\"\"\")\n",
    "# 聊天提示\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, \n",
    "     human_message_prompt])\n",
    "\n",
    "# 求最长公共子串\n",
    "def longest_common_substring(s1, s2):\n",
    "    # 获取两个字符串的长度\n",
    "    len_s1 = len(s1)\n",
    "    len_s2 = len(s2)\n",
    "\n",
    "    # 创建一个二维数组用来存储动态规划的结果\n",
    "    dp = [[0] * (len_s2 + 1) for _ in range(len_s1 + 1)]\n",
    "\n",
    "    # 初始化最大长度和结束位置\n",
    "    max_length = 0\n",
    "    end_pos = 0\n",
    "\n",
    "    # 填充动态规划表\n",
    "    for i in range(1, len_s1 + 1):\n",
    "        for j in range(1, len_s2 + 1):\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "                if dp[i][j] > max_length:\n",
    "                    max_length = dp[i][j]\n",
    "                    end_pos = i\n",
    "            else:\n",
    "                dp[i][j] = 0\n",
    "\n",
    "    # 提取最大公共子串\n",
    "    start_pos = end_pos - max_length\n",
    "    return s1[start_pos:end_pos]\n",
    "\n",
    "# 合并分类和问答提示为context提示\n",
    "def generate_context_prompt(all_dict):\n",
    "    question = all_dict[\"question\"]\n",
    "    question_classify_response = all_dict[\"context\"][\"question_classify_response\"]\n",
    "    question_retrieval_response = all_dict[\"context\"][\"question_retrieval_response\"]\n",
    "    \n",
    "    if len(question_classify_response) > 0:\n",
    "        question_classify_template = f\"\"\"你在回答中体现以下内容\n",
    "        {question_classify_response}\n",
    "        \"\"\"\n",
    "    else:\n",
    "        question_classify_template = \"\"\n",
    "    \n",
    "    if len(longest_common_substring(question,question_retrieval_response)) >=4:\n",
    "        question_retrieval_template = f\"\"\"工作经历有以下内容\n",
    "        {question_retrieval_response}\n",
    "        \"\"\"\n",
    "    else:\n",
    "        question_retrieval_template = f\"\"\"没有针对该问题的简历信息。\n",
    "        \"\"\"\n",
    "    return {\n",
    "        \"question\":question,\n",
    "        \"context\":f\"{question_classify_template}\\n\\n{question_retrieval_template}\\n\\n\"\n",
    "    }\n",
    "\n",
    "# 整体链\n",
    "final_chain = {\"question\": RunnablePassthrough(),\n",
    "               \"context\":  RunnableParallel(question_classify_response=question_classify_chain,\n",
    "                                            question_retrieval_response=question_retrieval_chain) \n",
    "} | RunnableLambda(generate_context_prompt)| prompt | chat | StrOutputParser() \n",
    "\n",
    "print(final_chain.invoke(\"介绍一下word weaver\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
