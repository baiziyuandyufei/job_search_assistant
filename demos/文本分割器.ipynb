{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(documents): 140\n",
      "page_content='我在自然语言处理领域积累了丰富的实践知识。我不仅熟悉传统算法如MaxEnt、LSTM和CRF，还对大语言模型有深入的理解和应用能力，特别是熟练掌握Transformers库、LangChain库。我在' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='rmers库、LangChain库。我在文本分类任务上成功微调过DistilBERT模型，并在实体识别任务上微调过Mistral7B模型。除此之外，我喜欢探索新技术，并在实践中积极使用fastGPT和' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='技术，并在实践中积极使用fastGPT和LangChain搭建个人本地问答系统。我具备良好的团队协作精神和沟通技巧，能够快速融入新的工作环境并推动项目的顺利进行。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='工作经历与精选项目\\r\\n对话系统设计 2024年5月至今\\r\\n大模型算法/LangChain、Prompt、RAG、Summarize、QA' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='•\\t基于LangChain的求职助手 项目链接' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='项目链接 https://baiziyuandyufei-langchain-self-stu-my-streamlit-example1-laktvh.streamlit.app/' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='该项目旨在开发一个基于 Langchain和 llama-v3-70b-instruct  模型的对话机器人，主要用于帮助用户回答 HR  提出的问题或陈述。项目涉及多项前沿技术，特别是针对简历' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='PDF  文档和 JD  描述网页等外部知识的有效利用。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='1. HR问题分类链：\\r\\n此步的目的是识别出特定问题，针对特定问题给出特定的提示，进而给出特定的回答。\\r\\n少样本提示模板如下：\\r\\n给出每个文本的类别，类别只能属于以下列出的一种\\r\\n\\r\\n- 离职原因' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='- 离职原因\\r\\n- 薪资\\r\\n- 外包&外协&外派&驻场\\r\\n- 兼职\\r\\n- 学历\\r\\n\\r\\n如果不属于以上类别，则类别名称为“其他”。\\r\\n\\r\\n例如：\\r\\n\\r\\n文本: 离职/换工作的原因' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='文本: 离职/换工作的原因\\r\\n类别: 离职原因\\r\\n\\r\\n文本: 你好，我们是外协岗位，在国家电网 南瑞工作的\\r\\n类别: 外包&外协&外派&驻场' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='类别: 外包&外协&外派&驻场\\r\\n\\r\\n文本: 但是我们应该最高30K，一般还达不到.\\r\\n类别: 薪资' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='类别: 薪资\\r\\n\\r\\n文本: 哈喽～本职位为线上兼职，一单一结款，根据自己时间自由接单，不耽误自己的主业，您看感兴趣嘛？\\r\\n类别: 兼职\\r\\n\\r\\n文本: 你好\\r\\n类别:\\r\\n2. 个人简历知识：' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='针对简历 PDF  文档和 JD  描述网页等外部资源，使用文档加载器和文档转换器将其内容提取并结构化处理。使用 FAISS' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='FAISS  向量存储器和检索器，将外部知识融入到对话中，提供更加精准和上下文相关的回答。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='- 简历文档加载。使用 UnstructuredWordDocumentLoader 加载Word文档。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='- 分档拆分。使用 `RecursiveCharacterTextSplitter`' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='拆分文档。关键参数解释如下：separators：定义多个分隔符。尽量使用多种分隔符有助于更细粒度地拆分文档，保证文本块的语义完整性和逻辑连贯性。chunk_size：设置为50字符，确保每个文本块' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='size：设置为50字符，确保每个文本块适中，利于后续处理和检索效率。chunk_overlap：设置为20字符，使文本块之间有部分重叠，有助于提高检索内容的相关性和语境理解。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='-' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='块向量化。向量化模型的选择与评测方法。在文本向量化中，使用paraphrase-multilingual-MiniLM-L12-v2对文本进行向量化，并评估模型的准确性。构建相关度数据集的方法包括通' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='型的准确性。构建相关度数据集的方法包括通过增删改一定比例的字符生成相关句子，同时随机生成不相关句子。针对每个实例组，计算向量化后的文本之间的相似度，并根据预先指定的阈值进行准确性评估，最终得出平均准确' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='定的阈值进行准确性评估，最终得出平均准确性，这有助于提高检索时的相关性。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='-' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='向量存储与检索。我使用了FAISS工具库，通过将文档集合转换为索引的方式实现了高效的文本检索。在检索过程中，我输入待检索的文本，并利用构建的索引进行相似度搜索，最终获取了与输入文本最相关的文档及其相' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='，最终获取了与输入文本最相关的文档及其相关性分数，并按相关性排序输出。此外，我还对检索结果进行了重排序，利用最长公共子串算法提高了结果的质量和相关性。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='3. 多轮交互与对话记忆：\\r\\n实现对话记忆功能，确保多轮对话中上下文信息的保留和连续性。\\r\\n4. 基于LCEL融合分类链与记忆链：' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='在我的项目中，我设计并实现了一种智能的求职助手，它能够根据用户提出的问题类型使用不同的提示，从而使LLM模型（大语言模型）生成更具个性化的回答。为了实现这一点，我引入了RunnableLambda链' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='，我引入了RunnableLambda链，具体过程如下：' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='-' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='首先，我定义了一系列模板，包括系统消息模板（SystemMessagePromptTemplate）和人类消息模板（HumanMessagePromptTemplate），这些模板以汉语进行交流，确' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='plate），这些模板以汉语进行交流，确保整个对话过程符合目标语言的要求。接着，我通过ChatPromptTemplate将这些消息模板组合成一个统一的聊天提示。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='-' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='然后，我使用了一个名为RunnableLambda的可运行函数，通过它来实现问题分类功能。具体而言，我创建了一个数据处理链，其中RunnableLambda根据输入问题调用self.question' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='据输入问题调用self.question_classify方法对问题进行分类。分类后的问题和原始问题一起被传递到下一个处理节点。根据不同的问题类别，该链条动态选择相应的提示，从而使得LLM模型可以生成' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='择相应的提示，从而使得LLM模型可以生成更准确和相关的回答。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='通过这种方法，我实现了一个智能的求职助手，它不仅能理解用户的多样化问题，还能根据问题的具体类型提供量身定制的回答。这种解决方案显著提高了用户互动的体验和回答的准确性。。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='5. API  服务与交互界面设计：' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='在本项目中，我构建了一个个人求职助手聊天机器人，旨在帮助用户模拟与HR的对话，提供专业的求职建议和回答。该应用基于Streamlit框架，实现了与大型语言模型llama-v3-70b-instruc' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='llama-v3-70b-instruct的交互。以下是本项目的API服务与交互界面设计说明。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='- 技术栈。Streamlit：用于快速构建交互式Web应用。LangChain' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='Fireworks：用于调用和管理语言模型。Dotenv：用于加载环境变量，确保敏感信息安全。Python：编程语言。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='-' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='API服务设计。环境变量配置：通过load_dotenv()函数加载环境变量，确保模型API密钥等敏感信息不被硬编码。语言模型初始化：使用ChatFireworks初始化llama-v3-70b-i' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='rks初始化llama-v3-70b-instruct模型，设置温度和top_p参数，保证生成响应的多样性和质量。提示模板配置：利用SystemMessagePromptTemplate和HumanM' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='romptTemplate和HumanMessagePromptTemplate定义系统和用户提示模板，使得模型能根据不同角色生成相应的回复。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='-' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='交互界面设计。页面布局：标题部分：通过st.title()设置应用的主标题和副标题，直观展示应用功能。页面描述：使用st.caption()简要描述应用的功能和特点。侧边栏：提供密码输入框、API申' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='和特点。侧边栏：提供密码输入框、API申请链接、源码链接以及在GitHub' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='Codespaces中打开的快捷链接。会话管理：初始化会话：在st.session_state中存储会话消息，初次加载时添加助手的欢迎消息。显示消息：通过遍历st.session_state.mes' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='st.session_state.messages，将所有会话消息展示在界面上。用户输入与响应生成：聊天输入表格：使用st.chat_input()获取用户输入，并通过海象运算符进行赋值和检查。消息处' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content=\"，并通过海象运算符进行赋值和检查。消息处理：将用户输入添加到会话消息中，调用对话链chain.invoke({'input':prompt})获取模型生成的响应，并将响应添加到会话消息中。\" metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='-' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='功能特点。实时对话：用户可以实时输入HR的问题，模型即时生成并返回相应的回复。会话记录：所有对话记录保存在会话状态中，用户可以查看整个对话的上下文。安全性：通过环境变量和密码输入框，确保API密钥等' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='过环境变量和密码输入框，确保API密钥等敏感信息的安全性。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='中科院信工所（非外协）2018年8月至2024年5月 \\r\\n自然语言处理工程师/短文本分类、短文本实体识别\\r\\n•\\t工作内容' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='我独自负责了两个关键的自然语言处理项目。首先是社交短文本分类项目，我完成了数据获取、语料清洗、模型构建和部署等任务。其次是开发高效的社交短文本实体识别系统，我利用Mistral' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='7B大语言模型进行实体信息提取，完成了整个项目的开发和实施。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='•\\t社交短文本实体识别项目' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='本项目旨在开发一种高效的社交短文本实体识别系统，通过使用Mistral 7B大语言模型，从社交短文本中准确提取日期、设施、人物、货币、组织、地点、产品和事件等实体信息。我利用Mistral' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='7B模型的强大语言理解和生成能力，并进行4位量化以降低计算资源需求，添加LoRA适配器以提升特定任务表现，并通过自定义回调函数实时监控训练效果。我在微调Mistral' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='7B大语言模型方面积累了丰富的项目经验，确保其在不同任务上的高效表现。该系统主要为其他项目组提供自然语言处理基础组件。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='1. 数据准备。\\r\\n训练集句子总量: 200\\r\\n验证集句子总量: 20\\r\\n测试集句子总量: 200\\r\\n类别总数: 19\\r\\n2. 提示模板\\r\\n根据实体标注任务，设计特征模板。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='Extract the entities for the following labels from the given text and provide the results in JSON' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='the results in JSON format' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='- Extract entities exactly as mentioned in the text.' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='- Return each entity under its label without creating new labels.' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='- Provide a list of entities for each label; if no entities are found, return an empty list.' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='- Accuracy and relevance are key.\\r\\nLabels:\\r\\n- ORG:Media\\r\\n- GPE:Population-Center\\r\\n- PER:Individual' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='- PER:Individual\\r\\n- GPE:Nation\\r\\n- ORG:Sports\\r\\n...\\r\\n3. 机器环境' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='...\\r\\n3. 机器环境\\r\\nDocker 环境配置，从github的Transformers库下载Dockerfile，build镜像。\\r\\nDirver Version: 535.104.05' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='CUDA Version: 12.2\\r\\nGPU Name: Tesla T4\\r\\nGPU Memory: 15360 MiB\\r\\n4. 基本原理' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='4. 基本原理\\r\\n- 使用BNB对Mistral-7b模型量化后加载到GPU。\\r\\n- 利用PEFT技术增加LoRA层，有监督微调模型参数。\\r\\n- 最大化next token概率。\\r\\n5. 参数配置' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='5. 参数配置\\r\\n- 周期数：3。\\r\\n- 批大小：4。\\r\\n- 累积梯度更新步数：2。\\r\\n6. 训练过程\\r\\n[75/75 1:39:05, Epoch 3/3]' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='Step\\tTraining Loss\\tValidation Loss\\r\\n10\\t1.061800\\t16.022060\\r\\n20\\t0.386200\\t19.186018' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='30\\t0.268000\\t20.003162\\r\\n40\\t0.255600\\t20.269028\\r\\n50\\t0.240800\\t20.377626\\r\\n60\\t0.225100\\t20.743212' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='70\\t0.214700\\t20.486006\\r\\n7. 推断\\r\\n加载量化基础模型Mistral-7b，设置生成任务相关参数，输入待标注句子，得到Json格式标注结果。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='max_new_tokens=200,\\r\\nearly_stopping=True,\\r\\npad_token_id=tokenizer.eos_token_id,' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='eos_token_id=tokenizer.convert_tokens_to_ids(\"}\"),\\r\\ntemperature=0.8,\\r\\ntop_k=50,\\r\\ntop_p=0.9,' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='top_p=0.9,\\r\\nrepetition_penalty=1.2\\r\\n8. 评测' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='去年“六一”前夕，总书记走进北京育英学校学生农场，看到孩子们正在开展农业种植活动。总书记说：“很多知识和道理都来自劳动、来自生活。引导孩子们从小树立劳动观念，培养劳动习惯，提高劳动能力，有利于他们更' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='培养劳动习惯，提高劳动能力，有利于他们更好地学习知识。”既有言传，又有身教，勤劳的意义愈发凸显.' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='{\\r\\n \"PER:Individual\": [\\r\\n   \"总书记\"\\r\\n ],\\r\\n \"ORG:Educational\": [\\r\\n   \"北京育英学校\",\\r\\n   \"北京育英学校学生农场\"\\r\\n ]' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content=']\\r\\n}\\r\\n•\\t社交短文本分类项目\\r\\n1. 数据的获取' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='- 爬取 sougou' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='词库词典，解码转为普通可读文本文件。作用为为后续基于词典预测文本类别。制作链接爬虫，记录链接地址和链接名称，构建链接库。作用为根据用户提供的类别名称快速检索到对应的文本语料。制作语料爬虫。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='提供两种爬虫形式。形式一：基于 scrapy  爬取链接库中的所有链接对应的语料，实现定期更新语料库。形式二：单链接爬虫。只爬取一个链接对应的全部语料。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='- 交互界面设计与制作。基于flask+jquery+bootstrap+ajax' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='制作链接库管理界面和爬虫界面。功能包括：增删改查链接，爬取按钮，爬取过程日志的显示，类目体系显示，类目数据量分布显示，类目下文本显示。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='2. 基于朴素贝叶斯模型净化训练语料\\r\\n- 商品标题领域和新闻标题领域选择贝努力还是多项式分类模型？本系统使用多项式。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='汉语分词与训练速度的关系。并没有使用去停用词或保留关键词，因为社交文本用词丰富，没有词表可囊括。只用词长和词形去掉没有意义的词语。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='-' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='进一步优化了训练数据，根据混淆矩阵分布均匀的列去除了一个类目，分布均匀的行去除了一个类目，以确保数据的平衡性。同时，我根据训练好的模型，找出了每个类别的关键词，作为该类别的代表特征，用于净化训练语料' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='，作为该类别的代表特征，用于净化训练语料。此外，我也过滤了数据量小于400的类目，以提高模型的泛化能力和分类效果。这些优化措施有助于提高模型对各类别的识别准确度和分类性能。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='- 获取各类别关键词。基于训练好的模型，找出每个类别的关键词。模型训练好后，找出各类别得分最高的词语，就是该类别的关键词，传统模型的优势就在这里。使用类别关键词净化训练语料。' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='3. 基于 distilbert base multilingual cased  模型构建文本分类模型' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='- 为什么要用 distilbert ？使用 DistilmBERT  模型的原因是它在与朴素贝叶斯模型相比具有更好的性能和效率。首先，DistilmBERT' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='是一个经过蒸馏的模型，相比于朴素贝叶斯模型，它能够捕捉更复杂的语言结构和语义信息，从而提高了分类任务的准确性。其次，DistilmBERT' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='在处理多语言文本时也表现出色，因为它是在包含104种不同语言的维基百科数据上训练的，具有更好的泛化能力。与 bert base chinese  相比，DistilmBERT' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n",
      "page_content='相比，DistilmBERT  的优势在于其更小的模型尺寸和更高的运行速度。虽然 BERT base chinese' metadata={'source': 'https://raw.githubusercontent.com/baiziyuandyufei/langchain-self-study-tutorial/main/jl.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredWordDocumentLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter,CharacterTextSplitter\n",
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "# 加载指定URL的内容\n",
    "loader = WebBaseLoader(\"\")\n",
    "raw_documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    add_start_index=False,\n",
    ")\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "print(f\"len(documents): {len(documents)}\")\n",
    "for document in documents[:100]:\n",
    "    print(document)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
