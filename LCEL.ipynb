{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': AIMessage(content='小白兔为什么总是开心？因为它知道它不会被猎杀，因为它是“兔”斯基！(Rabbit-Ski)\\n :)\\n\\n(请注意，这是一句 humor/梗话，不是事实。)', response_metadata={'token_usage': {'prompt_tokens': 22, 'total_tokens': 97, 'completion_tokens': 75}, 'model_name': 'accounts/fireworks/models/mixtral-8x7b-instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='run-2ca97496-53a8-4cbb-ad12-9ab942336362-0'),\n",
       " 'poem': AIMessage(content=\"小白兔在草地上，\\nPlaying in the green, green grass,\\nSoft and fluffy, full of fun,\\nHopping here and there, so fast.\\n\\nWith twinkling eyes and pink little nose,\\nNibbling on clover, carrots too,\\nIn the sunshine, basking,\\nLiving life, simple and true.\\n\\nDreaming under the moon's soft glow,\\nIn the world of nature, free to go,\\nThe little bunny, full of woe,\\nA symbol of peace, we should know.\", response_metadata={'token_usage': {'prompt_tokens': 24, 'total_tokens': 157, 'completion_tokens': 133}, 'model_name': 'accounts/fireworks/models/mixtral-8x7b-instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='run-ca01a33e-ac9c-456b-8765-47115035b4ab-0')}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "import os\n",
    "from langchain_fireworks import ChatFireworks\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# 使用Mistral-7b\n",
    "llm = ChatFireworks(model=\"accounts/fireworks/models/mixtral-8x7b-instruct\")\n",
    "# 定义笑话链\n",
    "joke_chain = ChatPromptTemplate.from_template(\"讲一句关于{topic}的笑话\")|llm\n",
    "# 定义诗歌链\n",
    "poem_chain = ChatPromptTemplate.from_template(\"写一首关于{topic}的短诗\")|llm\n",
    "# 通过RunnableParallel执行两个调用链\n",
    "map_chain = RunnableParallel(joke=joke_chain,poem=poem_chain)\n",
    "map_chain.invoke({\"topic\":\"小白兔\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The sum of 3 and 9 is 12. Is there anything else you would like to know? I'm here to help with any questions you have. Just let me know!\", response_metadata={'token_usage': {'prompt_tokens': 14, 'total_tokens': 55, 'completion_tokens': 41}, 'model_name': 'accounts/fireworks/models/mixtral-8x7b-instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='run-faae7829-ee8e-4ed7-850b-d82920093ea8-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_fireworks import ChatFireworks\n",
    "\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "def multiple_length_function(_dict):\n",
    "    return len(_dict[\"text1\"]) * len(_dict[\"text2\"])\n",
    "prompt = ChatPromptTemplate.from_template(\"What is {a}+{b}\")\n",
    "model = ChatFireworks(model=\"accounts/fireworks/models/mixtral-8x7b-instruct\")\n",
    "chain = {\"a\": itemgetter(\"foo\")|RunnableLambda(length_function),\n",
    "         \"b\": {\"text1\":itemgetter(\"foo\"), \"text2\":itemgetter(\"bar\")} | RunnableLambda(multiple_length_function)}|prompt|model\n",
    "chain.invoke({\"foo\":\"bar\",\"bar\":\"gah\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
