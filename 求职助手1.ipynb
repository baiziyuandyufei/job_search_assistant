{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"嗨，感谢您的邀请！我目前确实有换工作的意愿，想寻找一个挑战性的角色和良好的团队文化。您的团队是什么样的？有什么样的项目和目标？\"\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_fireworks import ChatFireworks\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3-70b-instruct\",temperature=0)\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(\"你是一个求职助手，用汉语交流。\")\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\"HR问或说：“{user_input}”，你用汉语回答：\")\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt,\n",
    "     human_message_prompt]\n",
    ")\n",
    "chain = chat_prompt|llm|StrOutputParser()\n",
    "text = \"\"\"\n",
    "请问，最近有换工作的意愿么？我们正在寻找一位团队伙伴。\n",
    "\"\"\"\n",
    "messages = chat_prompt.format_prompt(user_input=text)\n",
    "print(chain.invoke(messages))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本: 你好，这边是兼职，可在家/空闲时间接单。爬虫，代码实现/跑通，数据分析，图像算法等等。\n",
      "类别: 兼职\n",
      "文本: 你好，我们是软通动力正在以20-40K的薪资招聘大模型算法工程师(线上面试+周末双休)，看了你的简历，觉得与我们的岗位要求非常匹配～盼进一步沟通～\n",
      "类别: 薪资\n",
      "文本: 于先生，可以就你的经历详细说说么？\n",
      "类别: 其他\n",
      "文本: 您好，这个岗位是外派驻场性质的哦\n",
      "类别: 外包&外协&外派&驻场\n",
      "文本: 你好，我们正在诚聘nlp算法（外包银行），有兴趣聊聊吗\n",
      "类别: 外包&外协&外派&驻场\n",
      "文本: 离职状态吗？\n",
      "类别: 离职原因\n"
     ]
    }
   ],
   "source": [
    "from langchain_fireworks import ChatFireworks\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "llm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3-70b-instruct\",temperature=0)\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    FewShotPromptTemplate\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 示例样本 给出模板中使用的变量的值\n",
    "examples = [\n",
    "    {\"text\": \"离职/换工作的原因\",\"label\": \"离职原因\"},\n",
    "    {\"text\": \"你好，我们是外协岗位，在国家电网 南瑞工作的\",\"label\": \"外包&外协&外派&驻场\"},\n",
    "    {\"text\": \"但是我们应该最高30K，一般还达不到.\",\"label\": \"薪资\"},\n",
    "    {\"text\": \"哈喽～本职位为线上兼职，一单一结款，根据自己时间自由接单，不耽误自己的主业，您看感兴趣嘛？\",\"label\":\"兼职\"}\n",
    "]\n",
    "# 示例样本的模板 给出示例的具体格式\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "\"\"\"文本: {text}\n",
    "类别: {label}\n",
    "\"\"\"\n",
    ")\n",
    "# 放在所有示例之前的文字，用于描述任务\n",
    "prefix = \"\"\"\n",
    "给出每个文本的类别，类别只能属于以下列出的一种\n",
    "\n",
    "- 离职原因\n",
    "- 薪资\n",
    "- 外包&外协&外派&驻场\n",
    "- 兼职\n",
    "- 学历\n",
    "\n",
    "如果不属于以上类别，则类别名称为“其他”。\n",
    "\n",
    "例如：\n",
    "\"\"\"\n",
    "# 放在所有示例之后的文字，用于输入用户文本让LLM预测\n",
    "suffix = \"\"\"文本: {input}\\n类别:\n",
    "\"\"\"\n",
    "# 带有示例的提示模板\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples, # 示例列表\n",
    "    example_prompt=example_prompt, # 示例提示\n",
    "    prefix=prefix, # 放在所有示例之前的文字，用于描述任务\n",
    "    suffix=suffix, # 放在所有示例之后的文字，用于输入用户文本让LLM预测\n",
    "    input_variables=[\"input\"], # 用户的输入变量名列表\n",
    "    example_separator=\"\\n\" # 示例之间的分隔符\n",
    ")\n",
    "# 接收用户输入变量的值生成少样本提示\n",
    "# print(few_shot_prompt.format(input='你好'))\n",
    "chain = few_shot_prompt|llm|StrOutputParser()\n",
    "import re\n",
    "text_li = [\n",
    "    \"你好，这边是兼职，可在家/空闲时间接单。爬虫，代码实现/跑通，数据分析，图像算法等等。\",\n",
    "    \"你好，我们是软通动力正在以20-40K的薪资招聘大模型算法工程师(线上面试+周末双休)，看了你的简历，觉得与我们的岗位要求非常匹配～盼进一步沟通～\",\n",
    "    \"于先生，可以就你的经历详细说说么？\",\n",
    "    \"您好，这个岗位是外派驻场性质的哦\",\n",
    "    \"你好，我们正在诚聘nlp算法（外包银行），有兴趣聊聊吗\",\n",
    "    \"离职状态吗？\",\n",
    "]\n",
    "\n",
    "for text in text_li:\n",
    "    text = text.strip()\n",
    "    result = chain.invoke({\"input\":text})\n",
    "    result = re.sub('类别: ?','',result)\n",
    "    print(f\"文本: {text}\\n类别: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量长度: 384\n",
      "doc_result[0]的模: 0.9999999925347522\n",
      "doc_result[1]的模: 1.0000000043740562\n",
      "doc_result[0]与doc_result[1]之间的相似度: 0.9890947479077432\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import numpy as np\n",
    "load_dotenv()\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    # model_name=\"jinaai/jina-embeddings-v2-base-zh\",\n",
    "    # model_name = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True})\n",
    "text = '今天天气怎么样?'\n",
    "query_result = embedding_model.embed_query(text)\n",
    "print(f\"向量长度: {len(query_result)}\")\n",
    "text_li = ['How is the weather today?', '今天天气怎么样?']\n",
    "doc_result = embedding_model.embed_documents(text_li)\n",
    "print(f\"doc_result[0]的模: {np.linalg.norm(doc_result[0])}\")\n",
    "print(f\"doc_result[1]的模: {np.linalg.norm(doc_result[1])}\")\n",
    "cosine_similarity_normalized = np.dot(doc_result[0], doc_result[1])\n",
    "print(f\"doc_result[0]与doc_result[1]之间的相似度: {cosine_similarity_normalized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(documents): 234\n",
      "page_content='于飞 北京广渠门 17718329813 baiziyuandyufei@126.com' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='baiziyuandyufei' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='我在自然语言处理领域积累了丰富的实践知识。我不仅熟悉传统算法如MaxEnt、LSTM和CRF' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，还对大语言模型有深入的理解和应用能力' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，特别是熟练掌握Transformers库' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='、LangChain库。我在文本分类任务上成功微调过DistilBERT模型' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，并在实体识别任务上微调过Mistral7B模型。除此之外，我喜欢探索新技术' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，并在实践中积极使用fastGPT和LangChain搭建个人本地问答系统' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='。我具备良好的团队协作精神和沟通技巧' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，能够快速融入新的工作环境并推动项目的顺利进行。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='与精选项目\\n\\n居家补充业务技能 2024年5月至今' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='LLM应用于对话系统/Prompt、RAG、Summarize、QA\\n\\n求职助手项目' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='该项目旨在开发一个基于 Langchain和 llama-v3-70b-instruct' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='模型的对话机器人，主要用于帮助用户回答 HR' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='HR  提出的问题或陈述。项目涉及多项前沿技术，特别是针对简历 PDF  文档和 JD' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='PDF  文档和 JD  描述网页等外部知识的有效利用。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='1. 对HR问题进行分类' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='此步的目的是识别出特定问题，针对特定问题给出特定的提示，进而给出特定的回答。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='少样本提示模板如下：' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='给出每个文本的类别，类别只能属于以下列出的一种 - 离职原因 - 薪资 - 外包&外协&外派&驻场' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='- 薪资 - 外包&外协&外派&驻场 - 兼职 - 学历' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='- 兼职 - 学历 如果不属于以上类别，则类别名称为“其他”。 例如： 文本: 离职/换工作的原因' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='例如： 文本: 离职/换工作的原因 类别: 离职原因 文本: 你好，我们是外协岗位，在国家电网' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='你好，我们是外协岗位，在国家电网 南瑞工作的 类别: 外包&外协&外派&驻场 文本:' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='类别: 外包&外协&外派&驻场 文本: 但是我们应该最高30K，一般还达不到. 类别: 薪资' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='类别: 薪资 文本:' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='文本: 哈喽～本职位为线上兼职，一单一结款，根据自己时间自由接单，不耽误自己的主业，您看感兴趣嘛？' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='类别: 兼职 文本: 你好 类别:' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='2. 外部知识的融入：' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='针对简历 PDF  文档和 JD' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='文档和 JD  描述网页等外部资源，使用文档加载器和文档转换器将其内容提取并结构化处理。使用' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='FAISS  向量存储器和检索器，将外部知识融入到对话中，提供更加精准和上下文相关的回答。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='在项目中，通过使用外部的预训练模型和工具，实现了对Word文档中内容块的有效表示和检索' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，提升了用户查询的响应质量。具体而言，我使用了Hugging' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='Face提供的`jinaai/jina-embeddings-v2-base-zh`模型来生成文本' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='s-v2-base-zh`模型来生成文本的嵌入表示' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，以便根据用户输入查询相似的内容块' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，并为生成回复提供上下文支持。（1）加载预训练模型：使用Hugging' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='Face的`HuggingFaceEmbeddings`接口' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，加载`jinaai/jina-embeddings-v2-base-zh`模型。通过设置模型参数' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，使其在CPU上运行' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，并确保生成的嵌入向量经过归一化处理。这一步确保了模型能够高效地将自然语言文本转换为向量表示' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='。（2）文档内容块表示：将多个文本块（例如中文和英文的句子）转化为嵌入向量' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，并计算其L2范数。这一步骤将文档中的每个内容块表示为高维向量' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，便于后续的相似度计算。（3）相似度计算和内容检索：通过计算嵌入向量之间的余弦相似度' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，量化不同内容块之间的相似性。根据用户输入的查询文本，检索相似的内容块，并将这些内容块作为提示' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，并将这些内容块作为提示，输入到语言模型中' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，输入到语言模型中，以生成相关性较高的回复。这种方法不仅能够处理单一语言的内容检索' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，还能实现跨语言的比较和检索' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，提升了系统的灵活性和适用性。该项目展示了如何通过引入先进的预训练模型和工具' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，增强系统处理外部知识的能力，特别是在根据用户输入动态生成回复方面的应用。通过这种方式' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，可以有效地提高查询响应的准确性和相关性，显著提升用户体验。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='3. 多轮交互与对话记忆：\\n\\n实现对话记忆功能，确保多轮对话中上下文信息的保留和连续性。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='4. 组合链的使用：\\n\\n使用组合链技术，集成各个功能模块，完成对话机器人的完整代理功能。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='5. API  服务与交互界面设计：' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='将整个对话机器人封装为 LangServer API  服务，提供稳定高效的接口。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='设计用户交互界面，提供友好直观的用户体验。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='中科院信工所（非外协）2018年8月至2024年5月' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='自然语言处理工程师/短文本分类、短文本实体识别\\n\\n工作内容' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='我独自负责了两个关键的自然语言处理项目。首先是社交短文本分类项目' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，我完成了数据获取、语料清洗、模型构建和部署等任务。其次是开发高效的社交短文本实体识别系统' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，我利用Mistral' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='7B大语言模型进行实体信息提取，完成了整个项目的开发和实施。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='社交短文本实体识别项目' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='本项目旨在开发一种高效的社交短文本实体识别系统，通过使用Mistral' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='7B大语言模型，从社交短文本中准确提取日期、设施、人物、货币、组织、地点、产品和事件等实体信' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='息。我利用Mistral' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='7B模型的强大语言理解和生成能力，并进行4位量化以降低计算资源需求' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，并进行4位量化以降低计算资源需求，添加LoRA适配器以提升特定任务表现' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，添加LoRA适配器以提升特定任务表现，并通过自定义回调函数实时监控训练效果。我在微调Mistral' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='7B大语言模型方面积累了丰富的项目经验' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，确保其在不同任务上的高效表现。该系统主要为其他项目组提供自然语言处理基础组件。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='1. 数据准备。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='训练集句子总量: 200 验证集句子总量: 20 测试集句子总量: 200 类别总数: 19' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='2. 提示模板\\n\\n根据实体标注任务，设计特征模板。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='Extract the entities for the following labels' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='following labels from the given text and provide' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='text and provide the results in JSON format -' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='in JSON format - Extract entities exactly as' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='entities exactly as mentioned in the text. -' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='in the text. - Return each entity under its label' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='under its label without creating new labels. -' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='new labels. - Provide a list of entities for each' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='entities for each label; if no entities are' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='if no entities are found, return an empty list. -' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='an empty list. - Accuracy and relevance are key.' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='relevance are key. Labels: - ORG:Media -' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='- ORG:Media - GPE:Population-Center -' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='- PER:Individual - GPE:Nation - ORG:Sports ...' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='3. 机器环境' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='Docker' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='环境配置，从github的Transformers库下载Dockerfile，build镜像。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='Dirver Version: 535.104.05 CUDA Version: 12.2 GPU' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='Version: 12.2 GPU Name: Tesla T4 GPU Memory:' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='T4 GPU Memory: 15360 MiB' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='4. 基本原理\\n\\n使用BNB对Mistral-7b模型量化后加载到GPU。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='利用PEFT技术增加LoRA层，有监督微调模型参数。\\n\\n最大化next token概率。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='最大化next token概率。\\n\\n5. 参数配置\\n\\n周期数：3。\\n\\n批大小：4。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='周期数：3。\\n\\n批大小：4。\\n\\n累积梯度更新步数：2。\\n\\n6. 训练过程' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='[75/75 1:39:05, Epoch 3/3] Step\\tTraining' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredWordDocumentLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter,CharacterTextSplitter\n",
    "loader = UnstructuredWordDocumentLoader('/Users/feiyu/Downloads/于飞-简历.docx')\n",
    "raw_documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\",\"\\n\",\" \",\".\",\",\",\"\\u200b\",\"\\uff0c\",\"\\u3001\",\"\\uff0e\",\"\\u3002\",\"\",\"，\",\"。\"],\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    add_start_index=False,\n",
    ")\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "print(f\"len(documents): {len(documents)}\")\n",
    "for document in documents[:100]:\n",
    "    print(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26077841606621255 page_content='.' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "0.2200012558382256 page_content='，实现了近义词抽取' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "0.13318650292590983 page_content='”的地得“语法纠错项目' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "0.07882162020649575 page_content='爬取 sougou' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "db = FAISS.from_documents(documents=documents, embedding=embedding_model)\n",
    "print(f\"索引片段数: {db.index.ntotal}\")\n",
    "query = \"\"\"\n",
    "你对傻逼熟悉吗？\n",
    "\"\"\"\n",
    "docs_and_scores = db.similarity_search_with_relevance_scores(query,k=4)\n",
    "for doc,score in docs_and_scores:\n",
    "    print(score,doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"嗨，谢谢您的问候！实际上，我最近确实有换工作的意愿。当前单位的通勤路程对我来说不是很方便，距离我居住地较远，每天通勤需要花费很多时间和精力。所以，我正在寻找一份更适合我的工作，能够让我更好地平衡工作和生活。如果贵公司的团队能够提供更好的通勤条件，我非常感兴趣！\"\n"
     ]
    }
   ],
   "source": [
    "# 连接问题分类链与问答链\n",
    "from dotenv import load_dotenv\n",
    "from langchain_fireworks import ChatFireworks\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    FewShotPromptTemplate\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import re\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3-70b-instruct\",temperature=0)\n",
    "\n",
    "def question_classify(text):\n",
    "    response_dict = {\n",
    "        \"离职原因\": {\n",
    "            \"response\": \"有换工意愿，当前单位离我居住地通勤不便\",\n",
    "            \"examples\": [{\"text\": \"离职/换工作的原因\",\"label\": \"离职原因\"}]\n",
    "        },\n",
    "        \"薪资\": {\n",
    "            \"response\": \"我期望薪资为30K～40K\",\n",
    "            \"examples\": [{\"text\": \"但是我们应该最高30K，一般还达不到.\",\"label\": \"薪资\"}]\n",
    "        },\n",
    "        \"外包&外协&外派&驻场\": {\n",
    "            \"response\": \"职位的办公地点在哪？薪资多少？\",\n",
    "            \"examples\": [{\"text\": \"你好，我们是外协岗位，在国家电网 南瑞工作的\",\"label\": \"外包&外协&外派&驻场\"}]\n",
    "        },\n",
    "        \"兼职\": {\n",
    "            \"response\": \"职位的办公地点在哪？薪资多少，怎么结算？\",\n",
    "            \"examples\": [{\"text\": \"哈喽～本职位为线上兼职，一单一结款，根据自己时间自由接单，不耽误自己的主业，您看感兴趣嘛？\",\"label\":\"兼职\"}]\n",
    "        },\n",
    "        \"其他\": {\n",
    "            \"response\": \"\",\n",
    "            \"examples\": []\n",
    "        }\n",
    "    }\n",
    "\n",
    "    examples = []\n",
    "    for key in response_dict:\n",
    "        r_examples = response_dict[key][\"examples\"]\n",
    "        if len(r_examples) > 0:\n",
    "            examples.extend(r_examples)\n",
    "\n",
    "    example_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"文本: {text}\n",
    "    类别: {label}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    prefix = \"\"\"\n",
    "    给出每个文本的类别，类别只能属于以下列出的一种\n",
    "\n",
    "    - 离职原因\n",
    "    - 薪资\n",
    "    - 外包&外协&外派&驻场\n",
    "    - 兼职\n",
    "    - 学历\n",
    "\n",
    "    如果不属于以上类别，则类别名称为“其他”。\n",
    "\n",
    "    例如：\n",
    "    \"\"\"\n",
    "\n",
    "    suffix = \"\"\"文本: {input}\\n类别:\n",
    "    \"\"\"\n",
    "\n",
    "    few_shot_prompt = FewShotPromptTemplate(\n",
    "        examples=examples, # 示例列表\n",
    "        example_prompt=example_prompt, # 示例提示\n",
    "        prefix=prefix, # 放在所有示例之前的文字，用于描述任务\n",
    "        suffix=suffix, # 放在所有示例之后的文字，用于输入用户文本让LLM预测\n",
    "        input_variables=[\"input\"], # 用户的输入变量名列表\n",
    "        example_separator=\"\\n\" # 示例之间的分隔符\n",
    "    )\n",
    "\n",
    "    chain = few_shot_prompt|llm|StrOutputParser()\n",
    "    \n",
    "    label = \"\"\n",
    "    text = text.strip()\n",
    "    if len(text)>0:\n",
    "        label = chain.invoke({\"input\":text})\n",
    "        label = re.sub('类别: ?','',label)\n",
    "    label = label if label in response_dict else \"其他\"\n",
    "    return response_dict[label][\"response\"]\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(\"你是一个求职助手，用汉语交流。\")\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\"HR问或说: “{question}”，你在回答中体现一下内容: “{response}”。你用汉语回答: \")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt,\n",
    "     human_message_prompt])\n",
    "\n",
    "\n",
    "chain = {\"question\": itemgetter(\"input\"), \n",
    "         \"response\": itemgetter(\"input\")|RunnableLambda(question_classify)} | \\\n",
    "        prompt | llm | StrOutputParser()\n",
    "\n",
    "text = \"\"\"\n",
    "请问，最近有换工作的意愿么？我们正在寻找一位团队伙伴。\n",
    "\"\"\"\n",
    "print(chain.invoke({\"input\":text}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"嗨，谢谢您的问候！实际上，我最近确实有换工作的意愿。主要原因是我当前的公司离我居住地太远，通勤时间太长，影响了我的生活质量和工作效率。如果有机会加入您的团队，我非常感兴趣。\"\n"
     ]
    }
   ],
   "source": [
    "# 连接问题分类链与问答链\n",
    "from dotenv import load_dotenv\n",
    "from langchain_fireworks import ChatFireworks\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    FewShotPromptTemplate\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import re\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class JobAssistant:\n",
    "    def __init__(self, model_path=\"accounts/fireworks/models/llama-v3-70b-instruct\", \n",
    "                temperature=0.3,\n",
    "                top_p=0.3):\n",
    "        self.llm = ChatFireworks(model=model_path, temperature=temperature)\n",
    "        self.response_dict = {\n",
    "            \"离职原因\": {\n",
    "                \"response\": \"有换工意愿，上家公司离我居住地太远，通勤时间太长\",\n",
    "                \"examples\": [{\"text\": \"离职/换工作的原因\",\"label\": \"离职原因\"}]\n",
    "            },\n",
    "            \"薪资\": {\n",
    "                \"response\": \"我期望薪资为30K～40K\",\n",
    "                \"examples\": [{\"text\": \"但是我们应该最高30K，一般还达不到.\",\"label\": \"薪资\"}]\n",
    "            },\n",
    "            \"外包&外协&外派&驻场\": {\n",
    "                \"response\": \"职位的办公地点在哪？薪资多少？\",\n",
    "                \"examples\": [{\"text\": \"你好，我们是外协岗位，在国家电网 南瑞工作的\",\"label\": \"外包&外协&外派&驻场\"}]\n",
    "            },\n",
    "            \"兼职\": {\n",
    "                \"response\": \"职位的办公地点在哪？薪资多少，怎么结算？\",\n",
    "                \"examples\": [{\"text\": \"哈喽～本职位为线上兼职，一单一结款，根据自己时间自由接单，不耽误自己的主业，您看感兴趣嘛？\",\"label\":\"兼职\"}]\n",
    "            },\n",
    "            \"其他\": {\n",
    "                \"response\": \"\",\n",
    "                \"examples\": []\n",
    "            }\n",
    "        }\n",
    "\n",
    "        self.examples = []\n",
    "        for key in self.response_dict:\n",
    "            r_examples = self.response_dict[key][\"examples\"]\n",
    "            if len(r_examples) > 0:\n",
    "                self.examples.extend(r_examples)\n",
    "\n",
    "        self.example_prompt = PromptTemplate.from_template(\n",
    "            \"\"\"文本: {text}\n",
    "            类别: {label}\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        self.prefix = \"\"\"\n",
    "        给出每个文本的类别，类别只能属于以下列出的一种\n",
    "\n",
    "        - 离职原因\n",
    "        - 薪资\n",
    "        - 外包&外协&外派&驻场\n",
    "        - 兼职\n",
    "        - 学历\n",
    "\n",
    "        如果不属于以上类别，则类别名称为“其他”。\n",
    "\n",
    "        例如：\n",
    "        \"\"\"\n",
    "\n",
    "        self.suffix = \"\"\"文本: {input}\\n类别:\n",
    "        \"\"\"\n",
    "\n",
    "        self.few_shot_prompt = FewShotPromptTemplate(\n",
    "            examples=self.examples,\n",
    "            example_prompt=self.example_prompt,\n",
    "            prefix=self.prefix,\n",
    "            suffix=self.suffix,\n",
    "            input_variables=[\"input\"],\n",
    "            example_separator=\"\\n\"\n",
    "        )\n",
    "\n",
    "        self.chain = self.few_shot_prompt | self.llm | StrOutputParser()\n",
    "\n",
    "        self.system_message_prompt = SystemMessagePromptTemplate.from_template(\"你是一个求职助手，用汉语交流。\")\n",
    "        self.human_message_prompt = HumanMessagePromptTemplate.from_template(\"HR问或说: “{question}”，你在回答中体现一下内容: “{response}”。你用汉语回答: \")\n",
    "        self.prompt = ChatPromptTemplate.from_messages(\n",
    "            [self.system_message_prompt, self.human_message_prompt])\n",
    "\n",
    "        self.final_chain = {\"question\": itemgetter(\"input\"),\n",
    "                            \"response\": itemgetter(\"input\") | RunnableLambda(self.question_classify)} | \\\n",
    "                           self.prompt | self.llm | StrOutputParser()\n",
    "\n",
    "    def question_classify(self, text):\n",
    "        label = \"\"\n",
    "        text = text.strip()\n",
    "        if len(text) > 0:\n",
    "            label = self.chain.invoke({\"input\": text})\n",
    "            label = re.sub('类别: ?', '', label)\n",
    "        label = label if label in self.response_dict else \"其他\"\n",
    "        return self.response_dict[label][\"response\"]\n",
    "\n",
    "    def get_response(self, text):\n",
    "        return self.final_chain.invoke({\"input\": text})\n",
    "\n",
    "# 使用示例\n",
    "assistant = JobAssistant()\n",
    "text = \"请问，最近有换工作的意愿么？我们正在寻找一位团队伙伴。\"\n",
    "print(assistant.get_response(text))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
