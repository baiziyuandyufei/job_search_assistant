{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"嗨，感谢您的邀请！我目前确实有换工作的意愿，想寻找一个挑战性的角色和良好的团队文化。您的团队是什么样的？有什么样的项目和目标？\"\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_fireworks import ChatFireworks\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3-70b-instruct\",temperature=0)\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(\"你是一个求职助手，用汉语交流。\")\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\"HR问或说：“{user_input}”，你用汉语回答：\")\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt,\n",
    "     human_message_prompt]\n",
    ")\n",
    "chain = chat_prompt|llm|StrOutputParser()\n",
    "text = \"\"\"\n",
    "请问，最近有换工作的意愿么？我们正在寻找一位团队伙伴。\n",
    "\"\"\"\n",
    "messages = chat_prompt.format_prompt(user_input=text)\n",
    "print(chain.invoke(messages))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本: 你好，这边是兼职，可在家/空闲时间接单。爬虫，代码实现/跑通，数据分析，图像算法等等。\n",
      "类别: 兼职\n",
      "文本: 你好，我们是软通动力正在以20-40K的薪资招聘大模型算法工程师(线上面试+周末双休)，看了你的简历，觉得与我们的岗位要求非常匹配～盼进一步沟通～\n",
      "类别: 薪资\n",
      "文本: 于先生，可以就你的经历详细说说么？\n",
      "类别: 其他\n",
      "文本: 您好，这个岗位是外派驻场性质的哦\n",
      "类别: 外包&外协&外派&驻场\n",
      "文本: 你好，我们正在诚聘nlp算法（外包银行），有兴趣聊聊吗\n",
      "类别: 外包&外协&外派&驻场\n",
      "文本: 离职状态吗？\n",
      "类别: 离职原因\n"
     ]
    }
   ],
   "source": [
    "from langchain_fireworks import ChatFireworks\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "llm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3-70b-instruct\",temperature=0)\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    FewShotPromptTemplate\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 示例样本 给出模板中使用的变量的值\n",
    "examples = [\n",
    "    {\"text\": \"离职/换工作的原因\",\"label\": \"离职原因\"},\n",
    "    {\"text\": \"你好，我们是外协岗位，在国家电网 南瑞工作的\",\"label\": \"外包&外协&外派&驻场\"},\n",
    "    {\"text\": \"但是我们应该最高30K，一般还达不到.\",\"label\": \"薪资\"},\n",
    "    {\"text\": \"哈喽～本职位为线上兼职，一单一结款，根据自己时间自由接单，不耽误自己的主业，您看感兴趣嘛？\",\"label\":\"兼职\"}\n",
    "]\n",
    "# 示例样本的模板 给出示例的具体格式\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "\"\"\"文本: {text}\n",
    "类别: {label}\n",
    "\"\"\"\n",
    ")\n",
    "# 放在所有示例之前的文字，用于描述任务\n",
    "prefix = \"\"\"\n",
    "给出每个文本的类别，类别只能属于以下列出的一种\n",
    "\n",
    "- 离职原因\n",
    "- 薪资\n",
    "- 外包&外协&外派&驻场\n",
    "- 兼职\n",
    "- 学历\n",
    "\n",
    "如果不属于以上类别，则类别名称为“其他”。\n",
    "\n",
    "例如：\n",
    "\"\"\"\n",
    "# 放在所有示例之后的文字，用于输入用户文本让LLM预测\n",
    "suffix = \"\"\"文本: {input}\\n类别:\n",
    "\"\"\"\n",
    "# 带有示例的提示模板\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples, # 示例列表\n",
    "    example_prompt=example_prompt, # 示例提示\n",
    "    prefix=prefix, # 放在所有示例之前的文字，用于描述任务\n",
    "    suffix=suffix, # 放在所有示例之后的文字，用于输入用户文本让LLM预测\n",
    "    input_variables=[\"input\"], # 用户的输入变量名列表\n",
    "    example_separator=\"\\n\" # 示例之间的分隔符\n",
    ")\n",
    "# 接收用户输入变量的值生成少样本提示\n",
    "# print(few_shot_prompt.format(input='你好'))\n",
    "chain = few_shot_prompt|llm|StrOutputParser()\n",
    "import re\n",
    "text_li = [\n",
    "    \"你好，这边是兼职，可在家/空闲时间接单。爬虫，代码实现/跑通，数据分析，图像算法等等。\",\n",
    "    \"你好，我们是软通动力正在以20-40K的薪资招聘大模型算法工程师(线上面试+周末双休)，看了你的简历，觉得与我们的岗位要求非常匹配～盼进一步沟通～\",\n",
    "    \"于先生，可以就你的经历详细说说么？\",\n",
    "    \"您好，这个岗位是外派驻场性质的哦\",\n",
    "    \"你好，我们正在诚聘nlp算法（外包银行），有兴趣聊聊吗\",\n",
    "    \"离职状态吗？\",\n",
    "]\n",
    "\n",
    "for text in text_li:\n",
    "    text = text.strip()\n",
    "    result = chain.invoke({\"input\":text})\n",
    "    result = re.sub('类别: ?','',result)\n",
    "    print(f\"文本: {text}\\n类别: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/feiyu/miniconda3/envs/langchain/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/Users/feiyu/miniconda3/envs/langchain/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/feiyu/miniconda3/envs/langchain/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量长度: 384\n",
      "doc_result[0]的模: 0.9999999925347522\n",
      "doc_result[1]的模: 1.0000000043740562\n",
      "doc_result[0]与doc_result[1]之间的相似度: 0.9890947479077432\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import numpy as np\n",
    "load_dotenv()\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    # model_name=\"jinaai/jina-embeddings-v2-base-zh\",\n",
    "    # model_name = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True})\n",
    "text = '今天天气怎么样?'\n",
    "query_result = embedding_model.embed_query(text)\n",
    "print(f\"向量长度: {len(query_result)}\")\n",
    "text_li = ['How is the weather today?', '今天天气怎么样?']\n",
    "doc_result = embedding_model.embed_documents(text_li)\n",
    "print(f\"doc_result[0]的模: {np.linalg.norm(doc_result[0])}\")\n",
    "print(f\"doc_result[1]的模: {np.linalg.norm(doc_result[1])}\")\n",
    "cosine_similarity_normalized = np.dot(doc_result[0], doc_result[1])\n",
    "print(f\"doc_result[0]与doc_result[1]之间的相似度: {cosine_similarity_normalized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(documents): 282\n",
      "page_content='于飞 北京广渠门 17718329813 baiziyuandyufei@126.com' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='baiziyuandyufei' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='我在自然语言处理领域积累了丰富的实践知识。我不仅熟悉传统算法如MaxEnt、LSTM和CRF' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，还对大语言模型有深入的理解和应用能力' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，特别是熟练掌握Transformers库' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='、LangChain库。我在文本分类任务上成功微调过DistilBERT模型' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，并在实体识别任务上微调过Mistral7B模型。除此之外，我喜欢探索新技术' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，并在实践中积极使用fastGPT和LangChain搭建个人本地问答系统' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='。我具备良好的团队协作精神和沟通技巧' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，能够快速融入新的工作环境并推动项目的顺利进行。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='与精选项目\\n\\n对话系统设计 2024年5月至今' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='大模型算法/LangChain、Prompt、RAG、Summarize、QA' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='基于LangChain的求职助手 项目链接' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='https://baiziyuandyufei-langchain-self-stu-my-str' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='hain-self-stu-my-streamlit-example1-laktvh' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='.streamlit.app/' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='该项目旨在开发一个基于 Langchain和 llama-v3-70b-instruct' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='模型的对话机器人，主要用于帮助用户回答 HR' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='HR  提出的问题或陈述。项目涉及多项前沿技术，特别是针对简历 PDF  文档和 JD' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='PDF  文档和 JD  描述网页等外部知识的有效利用。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='1. HR问题分类链：' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='此步的目的是识别出特定问题，针对特定问题给出特定的提示，进而给出特定的回答。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='少样本提示模板如下：' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='给出每个文本的类别，类别只能属于以下列出的一种 - 离职原因 - 薪资 - 外包&外协&外派&驻场' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='- 薪资 - 外包&外协&外派&驻场 - 兼职 - 学历' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='- 兼职 - 学历 如果不属于以上类别，则类别名称为“其他”。 例如： 文本: 离职/换工作的原因' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='例如： 文本: 离职/换工作的原因 类别: 离职原因 文本: 你好，我们是外协岗位，在国家电网' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='你好，我们是外协岗位，在国家电网 南瑞工作的 类别: 外包&外协&外派&驻场 文本:' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='类别: 外包&外协&外派&驻场 文本: 但是我们应该最高30K，一般还达不到. 类别: 薪资' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='类别: 薪资 文本:' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='文本: 哈喽～本职位为线上兼职，一单一结款，根据自己时间自由接单，不耽误自己的主业，您看感兴趣嘛？' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='类别: 兼职 文本: 你好 类别:' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='2. 个人简历知识：' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='针对简历 PDF  文档和 JD' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='文档和 JD  描述网页等外部资源，使用文档加载器和文档转换器将其内容提取并结构化处理。使用' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='FAISS  向量存储器和检索器，将外部知识融入到对话中，提供更加精准和上下文相关的回答。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='简历文档加载。使用 UnstructuredWordDocumentLoader' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='加载Word文档。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='分档拆分。使用 `RecursiveCharacterTextSplitter`' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='拆分文档。关键参数解释如下：separators：定义多个分隔符' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='。尽量使用多种分隔符有助于更细粒度地拆分文档' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，保证文本块的语义完整性和逻辑连贯性。chunk_size：设置为50字符，确保每个文本块适中' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，确保每个文本块适中，利于后续处理和检索效率。chunk_overlap：设置为20字符' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，使文本块之间有部分重叠，有助于提高检索内容的相关性和语境理解。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='块向量化。向量化模型的选择与评测方法。在文本向量化中' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，使用paraphrase-multilingual-MiniLM-L12-v2对文本进行向量化' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，并评估模型的准确性。构建相关度数据集的方法包括通过增删改一定比例的字符生成相关句子' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，同时随机生成不相关句子。针对每个实例组，计算向量化后的文本之间的相似度' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，计算向量化后的文本之间的相似度，并根据预先指定的阈值进行准确性评估，最终得出平均准确性' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，最终得出平均准确性，这有助于提高检索时的相关性。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='向量存储与检索。我使用了FAISS工具库' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，通过将文档集合转换为索引的方式实现了高效的文本检索。在检索过程中，我输入待检索的文本' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，我输入待检索的文本，并利用构建的索引进行相似度搜索，最终获取了与输入文本最相关的文档及其相关性分数' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，并按相关性排序输出。此外，我还对检索结果进行了重排序' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，我还对检索结果进行了重排序，利用最长公共子串算法提高了结果的质量和相关性。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='3. 多轮交互与对话记忆：\\n\\n实现对话记忆功能，确保多轮对话中上下文信息的保留和连续性。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='4. 基于LCEL融合分类链与记忆链：' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='在我的项目中，我设计并实现了一种智能的求职助手，它能够根据用户提出的问题类型使用不同的提示' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，从而使LLM模型（大语言模型）生成更具个性化的回答。为了实现这一点' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，我引入了RunnableLambda链，具体过程如下：' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='首先，我定义了一系列模板' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，包括系统消息模板（SystemMessagePromptTemplate）和人类消息模板（Huma' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='emplate）和人类消息模板（HumanMessagePromptTemplate）' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，这些模板以汉语进行交流，确保整个对话过程符合目标语言的要求。接着' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，我通过ChatPromptTemplate将这些消息模板组合成一个统一的聊天提示。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='然后，我使用了一个名为RunnableLambda的可运行函数，通过它来实现问题分类功能。具体而言' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，通过它来实现问题分类功能。具体而言，我创建了一个数据处理链' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，我创建了一个数据处理链，其中RunnableLambda根据输入问题调用self' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='.question_classify方法对问题进行分类' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='。分类后的问题和原始问题一起被传递到下一个处理节点。根据不同的问题类别' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，该链条动态选择相应的提示，从而使得LLM模型可以生成更准确和相关的回答。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='通过这种方法，我实现了一个智能的求职助手，它不仅能理解用户的多样化问题' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，还能根据问题的具体类型提供量身定制的回答。这种解决方案显著提高了用户互动的体验和回答的准确性。。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='5. API  服务与交互界面设计：' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='在本项目中，我构建了一个个人求职助手聊天机器人，旨在帮助用户模拟与HR的对话' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，旨在帮助用户模拟与HR的对话，提供专业的求职建议和回答。该应用基于Streamlit框架' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，实现了与大型语言模型llama-v3-70b-instruct的交互' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='。以下是本项目的API服务与交互界面设计说明。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='技术栈。Streamlit：用于快速构建交互式Web应用。LangChain' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='Fireworks：用于调用和管理语言模型。Dotenv：用于加载环境变量' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，确保敏感信息安全。Python：编程语言。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='API服务设计。环境变量配置：通过load_dotenv()函数加载环境变量' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，确保模型API密钥等敏感信息不被硬编码' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='。语言模型初始化：使用ChatFireworks初始化llama-v3-70b-instruct模型' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，设置温度和top_p参数' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，保证生成响应的多样性和质量' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='。提示模板配置：利用SystemMessagePromptTemplate和HumanMessage' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='emplate和HumanMessagePromptTemplate定义系统和用户提示模板' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，使得模型能根据不同角色生成相应的回复。' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='交互界面设计。页面布局：标题部分：通过st' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='.title()设置应用的主标题和副标题，直观展示应用功能。页面描述：使用st' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='.caption()简要描述应用的功能和特点。侧边栏：提供密码输入框、API申请链接' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='、API申请链接、源码链接以及在GitHub' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='Codespaces中打开的快捷链接。会话管理：初始化会话：在st' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='.session_state中存储会话消息，初次加载时添加助手的欢迎消息。显示消息：通过遍历st' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='.session_state' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='.messages，将所有会话消息展示在界面上。用户输入与响应生成：聊天输入表格：使用st' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='.chat_input()获取用户输入' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content='，并通过海象运算符进行赋值和检查。消息处理：将用户输入添加到会话消息中，调用对话链chain' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "page_content=\".invoke({'input':prompt})获取模型生成的响应，并将响应添加到会话消息中。\" metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredWordDocumentLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter,CharacterTextSplitter\n",
    "loader = UnstructuredWordDocumentLoader('/Users/feiyu/Downloads/于飞-简历.docx')\n",
    "raw_documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\",\"\\n\",\" \",\".\",\",\",\"\\u200b\",\"\\uff0c\",\"\\u3001\",\"\\uff0e\",\"\\u3002\",\"\",\"，\",\"。\"],\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    add_start_index=False,\n",
    ")\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "print(f\"len(documents): {len(documents)}\")\n",
    "for document in documents[:100]:\n",
    "    print(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "索引片段数: 282\n",
      "0.5480533585651948 page_content='.' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "0.3407815217627431 page_content='爬取 sougou' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "0.31435262390756236 page_content='类别: 兼职 文本: 你好 类别:' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n",
      "0.2112758466721062 page_content='https://baiziyuandyufei-langchain-self-stu-my-str' metadata={'source': '/Users/feiyu/Downloads/于飞-简历.docx'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "db = FAISS.from_documents(documents=documents, embedding=embedding_model)\n",
    "print(f\"索引片段数: {db.index.ntotal}\")\n",
    "query = \"\"\"\n",
    "自我介绍一下\n",
    "\"\"\"\n",
    "docs_and_scores = db.similarity_search_with_relevance_scores(query,k=4)\n",
    "for doc,score in docs_and_scores:\n",
    "    print(score,doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"嗨，谢谢您的问候！实际上，我最近确实有换工作的意愿。当前单位的通勤路程对我来说不是很方便，距离我居住地较远，每天通勤需要花费很多时间和精力。所以，我正在寻找一份更适合我的工作，能够让我更好地平衡工作和生活。如果贵公司的团队能够提供更好的通勤条件，我非常感兴趣！\"\n"
     ]
    }
   ],
   "source": [
    "# 连接问题分类链与问答链\n",
    "from dotenv import load_dotenv\n",
    "from langchain_fireworks import ChatFireworks\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    FewShotPromptTemplate\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import re\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3-70b-instruct\",temperature=0)\n",
    "\n",
    "def question_classify(text):\n",
    "    response_dict = {\n",
    "        \"离职原因\": {\n",
    "            \"response\": \"有换工意愿，当前单位离我居住地通勤不便\",\n",
    "            \"examples\": [{\"text\": \"离职/换工作的原因\",\"label\": \"离职原因\"}]\n",
    "        },\n",
    "        \"薪资\": {\n",
    "            \"response\": \"我期望薪资为30K～40K\",\n",
    "            \"examples\": [{\"text\": \"但是我们应该最高30K，一般还达不到.\",\"label\": \"薪资\"}]\n",
    "        },\n",
    "        \"外包&外协&外派&驻场\": {\n",
    "            \"response\": \"职位的办公地点在哪？薪资多少？\",\n",
    "            \"examples\": [{\"text\": \"你好，我们是外协岗位，在国家电网 南瑞工作的\",\"label\": \"外包&外协&外派&驻场\"}]\n",
    "        },\n",
    "        \"兼职\": {\n",
    "            \"response\": \"职位的办公地点在哪？薪资多少，怎么结算？\",\n",
    "            \"examples\": [{\"text\": \"哈喽～本职位为线上兼职，一单一结款，根据自己时间自由接单，不耽误自己的主业，您看感兴趣嘛？\",\"label\":\"兼职\"}]\n",
    "        },\n",
    "        \"其他\": {\n",
    "            \"response\": \"\",\n",
    "            \"examples\": []\n",
    "        }\n",
    "    }\n",
    "\n",
    "    examples = []\n",
    "    for key in response_dict:\n",
    "        r_examples = response_dict[key][\"examples\"]\n",
    "        if len(r_examples) > 0:\n",
    "            examples.extend(r_examples)\n",
    "\n",
    "    example_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"文本: {text}\n",
    "    类别: {label}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    prefix = \"\"\"\n",
    "    给出每个文本的类别，类别只能属于以下列出的一种\n",
    "\n",
    "    - 离职原因\n",
    "    - 薪资\n",
    "    - 外包&外协&外派&驻场\n",
    "    - 兼职\n",
    "    - 学历\n",
    "\n",
    "    如果不属于以上类别，则类别名称为“其他”。\n",
    "\n",
    "    例如：\n",
    "    \"\"\"\n",
    "\n",
    "    suffix = \"\"\"文本: {input}\\n类别:\n",
    "    \"\"\"\n",
    "\n",
    "    few_shot_prompt = FewShotPromptTemplate(\n",
    "        examples=examples, # 示例列表\n",
    "        example_prompt=example_prompt, # 示例提示\n",
    "        prefix=prefix, # 放在所有示例之前的文字，用于描述任务\n",
    "        suffix=suffix, # 放在所有示例之后的文字，用于输入用户文本让LLM预测\n",
    "        input_variables=[\"input\"], # 用户的输入变量名列表\n",
    "        example_separator=\"\\n\" # 示例之间的分隔符\n",
    "    )\n",
    "\n",
    "    chain = few_shot_prompt|llm|StrOutputParser()\n",
    "    \n",
    "    label = \"\"\n",
    "    text = text.strip()\n",
    "    if len(text)>0:\n",
    "        label = chain.invoke({\"input\":text})\n",
    "        label = re.sub('类别: ?','',label)\n",
    "    label = label if label in response_dict else \"其他\"\n",
    "    return response_dict[label][\"response\"]\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(\"你是一个求职助手，用汉语交流。\")\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\"HR问或说: “{question}”，你在回答中体现一下内容: “{response}”。你用汉语回答: \")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt,\n",
    "     human_message_prompt])\n",
    "\n",
    "\n",
    "chain = {\"question\": itemgetter(\"input\"), \n",
    "         \"response\": itemgetter(\"input\")|RunnableLambda(question_classify)} | \\\n",
    "        prompt | llm | StrOutputParser()\n",
    "\n",
    "text = \"\"\"\n",
    "请问，最近有换工作的意愿么？我们正在寻找一位团队伙伴。\n",
    "\"\"\"\n",
    "print(chain.invoke({\"input\":text}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"嗨，谢谢您的问候！实际上，我最近确实有换工作的意愿。主要原因是我当前的公司离我居住地太远，通勤时间太长，影响了我的生活质量和工作效率。如果有机会加入您的团队，我非常感兴趣。\"\n"
     ]
    }
   ],
   "source": [
    "# 连接问题分类链与问答链\n",
    "from dotenv import load_dotenv\n",
    "from langchain_fireworks import ChatFireworks\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    FewShotPromptTemplate\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import re\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class JobAssistant:\n",
    "    def __init__(self, model_path=\"accounts/fireworks/models/llama-v3-70b-instruct\", \n",
    "                temperature=0.3,\n",
    "                top_p=0.3):\n",
    "        self.llm = ChatFireworks(model=model_path, temperature=temperature)\n",
    "        self.response_dict = {\n",
    "            \"离职原因\": {\n",
    "                \"response\": \"有换工意愿，上家公司离我居住地太远，通勤时间太长\",\n",
    "                \"examples\": [{\"text\": \"离职/换工作的原因\",\"label\": \"离职原因\"}]\n",
    "            },\n",
    "            \"薪资\": {\n",
    "                \"response\": \"我期望薪资为30K～40K\",\n",
    "                \"examples\": [{\"text\": \"但是我们应该最高30K，一般还达不到.\",\"label\": \"薪资\"}]\n",
    "            },\n",
    "            \"外包&外协&外派&驻场\": {\n",
    "                \"response\": \"职位的办公地点在哪？薪资多少？\",\n",
    "                \"examples\": [{\"text\": \"你好，我们是外协岗位，在国家电网 南瑞工作的\",\"label\": \"外包&外协&外派&驻场\"}]\n",
    "            },\n",
    "            \"兼职\": {\n",
    "                \"response\": \"职位的办公地点在哪？薪资多少，怎么结算？\",\n",
    "                \"examples\": [{\"text\": \"哈喽～本职位为线上兼职，一单一结款，根据自己时间自由接单，不耽误自己的主业，您看感兴趣嘛？\",\"label\":\"兼职\"}]\n",
    "            },\n",
    "            \"其他\": {\n",
    "                \"response\": \"\",\n",
    "                \"examples\": []\n",
    "            }\n",
    "        }\n",
    "\n",
    "        self.examples = []\n",
    "        for key in self.response_dict:\n",
    "            r_examples = self.response_dict[key][\"examples\"]\n",
    "            if len(r_examples) > 0:\n",
    "                self.examples.extend(r_examples)\n",
    "\n",
    "        self.example_prompt = PromptTemplate.from_template(\n",
    "            \"\"\"文本: {text}\n",
    "            类别: {label}\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        self.prefix = \"\"\"\n",
    "        给出每个文本的类别，类别只能属于以下列出的一种\n",
    "\n",
    "        - 离职原因\n",
    "        - 薪资\n",
    "        - 外包&外协&外派&驻场\n",
    "        - 兼职\n",
    "        - 学历\n",
    "\n",
    "        如果不属于以上类别，则类别名称为“其他”。\n",
    "\n",
    "        例如：\n",
    "        \"\"\"\n",
    "\n",
    "        self.suffix = \"\"\"文本: {input}\\n类别:\n",
    "        \"\"\"\n",
    "\n",
    "        self.few_shot_prompt = FewShotPromptTemplate(\n",
    "            examples=self.examples,\n",
    "            example_prompt=self.example_prompt,\n",
    "            prefix=self.prefix,\n",
    "            suffix=self.suffix,\n",
    "            input_variables=[\"input\"],\n",
    "            example_separator=\"\\n\"\n",
    "        )\n",
    "\n",
    "        self.chain = self.few_shot_prompt | self.llm | StrOutputParser()\n",
    "\n",
    "        self.system_message_prompt = SystemMessagePromptTemplate.from_template(\"你是一个求职助手，用汉语交流。\")\n",
    "        self.human_message_prompt = HumanMessagePromptTemplate.from_template(\"HR问或说: “{question}”，你在回答中体现一下内容: “{response}”。你用汉语回答: \")\n",
    "        self.prompt = ChatPromptTemplate.from_messages(\n",
    "            [self.system_message_prompt, self.human_message_prompt])\n",
    "\n",
    "        self.final_chain = {\"question\": itemgetter(\"input\"),\n",
    "                            \"response\": itemgetter(\"input\") | RunnableLambda(self.question_classify)} | \\\n",
    "                           self.prompt | self.llm | StrOutputParser()\n",
    "\n",
    "    def question_classify(self, text):\n",
    "        label = \"\"\n",
    "        text = text.strip()\n",
    "        if len(text) > 0:\n",
    "            label = self.chain.invoke({\"input\": text})\n",
    "            label = re.sub('类别: ?', '', label)\n",
    "        label = label if label in self.response_dict else \"其他\"\n",
    "        return self.response_dict[label][\"response\"]\n",
    "\n",
    "    def get_response(self, text):\n",
    "        return self.final_chain.invoke({\"input\": text})\n",
    "\n",
    "# 使用示例\n",
    "assistant = JobAssistant()\n",
    "text = \"请问，最近有换工作的意愿么？我们正在寻找一位团队伙伴。\"\n",
    "print(assistant.get_response(text))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
